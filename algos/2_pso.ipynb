{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"01e799f84bc3439db6cf304f25702b0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"063b64c4d1e7438287388b6a07992e7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"06af3150a7314a259d247dda4b878f70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2afb929be5f443dbaabfe39bdb71c74f","max":127466,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2467ba26ff114a718b96306269420308","value":127466}},"06ed37e0be254c0189af075e6e943c0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07a2d020c1b24bfb84a9505034b11c97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_77efa2266ac64ccbac74f9072f0f6628","max":1030740,"min":0,"orientation":"horizontal","style":"IPY_MODEL_063b64c4d1e7438287388b6a07992e7d","value":1030740}},"07b52e5be6f74c09a305e4e17f403f24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e65f4b01200429bbe8c010d8b267015","IPY_MODEL_3880332f4227484fa6421611d48ef719","IPY_MODEL_445bb174bfc44c6db6256aba46364967"],"layout":"IPY_MODEL_b1606dad0963400cb8c0473e59c9237a"}},"07bc19ab1dfe4247bfa380903a78cb80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0814abbe10e342f3bed435e821e8e1d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08709503aef84033be1ed38a52c5e699":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1d8f71c066e4071ba3e1108edb5d30b","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37f4360caa0f4f5388eb03c693e70b6a","value":2000}},"0898ea20ddf946acbc754ca6decbaf0c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b993e16b7504a7b9e1a67352c1d987f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0cb0e55cc2dd4d1591715fa1e92d9eeb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e74182d4a204fefbe73affba0cc43ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0eb6358df9224c41b98890b8ef12d179":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b059ae6e0f2b4a57913df840b5963267","IPY_MODEL_db73a479e8814d03b51e0d1ab767bb87","IPY_MODEL_33298c79df194c97b2fee5315781881d"],"layout":"IPY_MODEL_96e2f4cbb1104355a29813f7b7757bd9"}},"12028dbde537431990be9d20233fe8c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1230770bfb384fb3b32f9bcf94b8e09e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_96a20b625667406a8143481c708f3100","IPY_MODEL_28441b71a49d4dd6b587021b6e664ab0","IPY_MODEL_2d2cbb1fec3d4ce29a8b47106b1ba49a"],"layout":"IPY_MODEL_6fbb3f23036646d284b48f7ce5c085f7"}},"12b4d4ffc36545c1a07855ea78c28395":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12dd060dfe67444182954afb162233c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7db60b3d04ed4302be036431f8492d6f","placeholder":"​","style":"IPY_MODEL_53cb5d415a514317890bd667ae8252e0","value":" 3000/3000 [00:00&lt;00:00, 4072.40 examples/s]"}},"158fcc41bcb842abbd0319c8a12afcea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9a5a93cd9a645a0837ec5cd5643b013","placeholder":"​","style":"IPY_MODEL_6e385ddfcdea4beb893f6d2e460964bf","value":"Generating train split: 100%"}},"159eb7b4b5f044449a6200b2f3d705ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16c30a0fbbae409db96fedfe9f003cd0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"179b05cba9e64bb4bcad2d27400b0328":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b8860dbbce04406be1519ba32faa845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c5f32f73fc9448183d4ea79d0eb57ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_996b49e8d8c34a6fbee52f7b5879ab93","placeholder":"​","style":"IPY_MODEL_415b1a367225474aa637e888bd69cd97","value":" 268M/268M [00:02&lt;00:00, 160MB/s]"}},"1c6f0e5be2514066a7e89129b220872d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e883cdefc0a240b68d1dcf5b2c599293","placeholder":"​","style":"IPY_MODEL_0814abbe10e342f3bed435e821e8e1d1","value":"tokenizer.json: 100%"}},"1cdb7122235a4c778c063657381c5d74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2467ba26ff114a718b96306269420308":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24dbd724412445178395ec466526f43a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8560bee85b904b1d8f598f61457370c8","placeholder":"​","style":"IPY_MODEL_5d364ac20ca5477c846f45bed79c45b9","value":" 232k/232k [00:00&lt;00:00, 1.88MB/s]"}},"28034f6e8ae345c3a0d37354a74addd1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2816733a86a24a42abcd0069dfc04a45":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28441b71a49d4dd6b587021b6e664ab0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e844fceae052449d97b63b39ed2b9a58","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0cb0e55cc2dd4d1591715fa1e92d9eeb","value":483}},"297c57771105417fb267192c398e6228":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_582af8bfa8f64bd1ac2826729c10adcc","placeholder":"​","style":"IPY_MODEL_81db8ca32a57451b825a6c0c1b9eb732","value":"vocab.txt: 100%"}},"29b7d157f3f245eca4791f37a2fbc873":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a2bc9c7374b427aa36809e1b4b2e2c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2afb929be5f443dbaabfe39bdb71c74f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b8c007f616d4a30bca8b0c46f32235c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_158fcc41bcb842abbd0319c8a12afcea","IPY_MODEL_3ec2cecfbc724850b37975410e9698b3","IPY_MODEL_4d573bc4d84749839a8ffb56c5f21ca5"],"layout":"IPY_MODEL_c2e4eaabb8234e84a179ed755f0dcb79"}},"2d2cbb1fec3d4ce29a8b47106b1ba49a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e913b671df6492383acefc1acbf5ba2","placeholder":"​","style":"IPY_MODEL_07bc19ab1dfe4247bfa380903a78cb80","value":" 483/483 [00:00&lt;00:00, 25.7kB/s]"}},"324291ee005648ceb01e72bd0533c404":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33298c79df194c97b2fee5315781881d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88e5a73c6a7b4362be1fc8da7011b430","placeholder":"​","style":"IPY_MODEL_c561d5fab6904adb9db1d92e3f8baa73","value":" 2000/2000 [00:00&lt;00:00, 92745.09 examples/s]"}},"34ec4963ffac4bc8b2d18dc084c9e98f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37f4360caa0f4f5388eb03c693e70b6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3880332f4227484fa6421611d48ef719":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7b298d3caf34dceab2931479b83c2ca","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47b3b3394e614bf39d825d54d398d26d","value":48}},"3a94252119b14f31adfdc54f92067933":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b3febbecfad420db7dd08bca8e05e3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dbdeee9f7c44314b1579b7d48ebab16","placeholder":"​","style":"IPY_MODEL_0e74182d4a204fefbe73affba0cc43ed","value":"Downloading builder script: "}},"3d12a9209ea14b2694063e0ff8a4663b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ec2cecfbc724850b37975410e9698b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8ad2bd72a2b4030a47d2acebf67f4e7","max":16000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c92f3e1bb0f47d993da0be07cda85a0","value":16000}},"3fbda3319fe34005a5251eb90567d96b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed95141e71b648eda10476c71bf90e08","placeholder":"​","style":"IPY_MODEL_3d12a9209ea14b2694063e0ff8a4663b","value":"Map: 100%"}},"4032ae6a852745ec9532288f13ea3652":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbc4693292bc460a81dfb36ab29227a2","IPY_MODEL_67ece0d9acf5466a9d040fe6c92197b2","IPY_MODEL_e46cf2250ea74824b9507a35fdea8686"],"layout":"IPY_MODEL_b2c0760361b0421da2f9e11927f09961"}},"415b1a367225474aa637e888bd69cd97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41ea4b64b50d4265a931732e773f1b0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65f39a6db5fb449283971d90852d91ec","placeholder":"​","style":"IPY_MODEL_54b11055fb6a49f987354949c1a8cf46","value":" 9.05k/? [00:00&lt;00:00, 339kB/s]"}},"445bb174bfc44c6db6256aba46364967":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c844aa6328cc44f9b5d80a265c390abf","placeholder":"​","style":"IPY_MODEL_77adb596b0e8486b80f674a2b0ae3998","value":" 48.0/48.0 [00:00&lt;00:00, 3.20kB/s]"}},"454f27f6c02f41928434c6073e2739ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_179b05cba9e64bb4bcad2d27400b0328","placeholder":"​","style":"IPY_MODEL_1b8860dbbce04406be1519ba32faa845","value":" 1.03M/1.03M [00:01&lt;00:00, 904kB/s]"}},"4553ff3aa4c94601b5bd5557bb18012b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc4d64e7a7084064a1ed92dcb3b80b38","placeholder":"​","style":"IPY_MODEL_dd7eafcdef634698a63dccf812ebe293","value":"model.safetensors: 100%"}},"47b3b3394e614bf39d825d54d398d26d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4aefd248c1f04d1fa5114e4a658e66fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4553e8d6d174ec199da4f40ca6c6213","placeholder":"​","style":"IPY_MODEL_d53150fb5b594fedb37d0e7cfa98f4b1","value":" 2000/2000 [00:00&lt;00:00, 3853.86 examples/s]"}},"4d573bc4d84749839a8ffb56c5f21ca5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34ec4963ffac4bc8b2d18dc084c9e98f","placeholder":"​","style":"IPY_MODEL_818a17048f394809aace5d7000887752","value":" 16000/16000 [00:00&lt;00:00, 160750.19 examples/s]"}},"4d998081ed04452c91ca7cf72034aefd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c26dad5f2484e8cae8d02c5a137a3e9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_867cf3f6144e496b89748bc2bd7b074b","value":1}},"50a5a0d019534a779d8228e477efb919":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51f2bd3d567f45dba347df0879656300":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_297c57771105417fb267192c398e6228","IPY_MODEL_82d3fe5bec4a4dd68372339324eb95eb","IPY_MODEL_24dbd724412445178395ec466526f43a"],"layout":"IPY_MODEL_2816733a86a24a42abcd0069dfc04a45"}},"53cb5d415a514317890bd667ae8252e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54b11055fb6a49f987354949c1a8cf46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"553f67fcb6044edf8365b6e773baf8a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"582af8bfa8f64bd1ac2826729c10adcc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5886ae8327044265ba840f04ca93064e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5928e138001749e8a1bf2846cc35c1bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d364ac20ca5477c846f45bed79c45b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5e29fdf7446444d4b1f850c077be3d53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16c30a0fbbae409db96fedfe9f003cd0","placeholder":"​","style":"IPY_MODEL_a29cbb282062498699c6e70101c0aa40","value":"split/train-00000-of-00001.parquet: 100%"}},"5f56c1ed9b2142ac99fe9c93cf7dfc62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9d9c3a693964d9bb6f1572bc03c770a","placeholder":"​","style":"IPY_MODEL_7bd44f1a972a4e858abdd2181e6d7142","value":"README.md: "}},"60b04b567e2b49e8bc94e87eb6af67a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fbda3319fe34005a5251eb90567d96b","IPY_MODEL_08709503aef84033be1ed38a52c5e699","IPY_MODEL_4aefd248c1f04d1fa5114e4a658e66fe"],"layout":"IPY_MODEL_01e799f84bc3439db6cf304f25702b0b"}},"635b42b4c7964febb4a664cc1e0c012c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6ff67757e95d4a6e8a7c2835c1add4d1","IPY_MODEL_cd3e423a32a242c5b33b5ccf13e69567","IPY_MODEL_12dd060dfe67444182954afb162233c6"],"layout":"IPY_MODEL_c81b239d3a3e4640b3de9729bd398c9b"}},"647299c5e28846ea9ff20b417b26ef67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65e6952fd45e4c4f9d688a2e51973b0a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_91a47c5a2d8542febf579b3f11fe4b9a","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c89f3099e5ba473e8dd9678678c1f45c","value":2000}},"65f39a6db5fb449283971d90852d91ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67ece0d9acf5466a9d040fe6c92197b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12028dbde537431990be9d20233fe8c8","max":128987,"min":0,"orientation":"horizontal","style":"IPY_MODEL_902747af7bf640bc9a312b4252a469fa","value":128987}},"689168d3b6e540aba2df17e2b7d833dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e385ddfcdea4beb893f6d2e460964bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e65f4b01200429bbe8c010d8b267015":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a94252119b14f31adfdc54f92067933","placeholder":"​","style":"IPY_MODEL_8c50d564862043bcbbfb2ff92b876c14","value":"tokenizer_config.json: 100%"}},"6f6ab1c34c014e64914ce51118952459":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_647299c5e28846ea9ff20b417b26ef67","placeholder":"​","style":"IPY_MODEL_96bfe5d6c1c7483689e9144d5d2509db","value":" 4.20k/? [00:00&lt;00:00, 157kB/s]"}},"6fbb3f23036646d284b48f7ce5c085f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ff67757e95d4a6e8a7c2835c1add4d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_689168d3b6e540aba2df17e2b7d833dc","placeholder":"​","style":"IPY_MODEL_ce191357312f4804b51cc602d086894d","value":"Map: 100%"}},"728fbe0c1c694361a9a3f206916fc94c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"76c72810e7124c1c8c48cd9df89a972b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_945ee263eb264b67971c754c344672f6","placeholder":"​","style":"IPY_MODEL_9af8b6cd14a8485d9852d78d14000a1d","value":"split/validation-00000-of-00001.parquet: 100%"}},"77adb596b0e8486b80f674a2b0ae3998":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77efa2266ac64ccbac74f9072f0f6628":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bd44f1a972a4e858abdd2181e6d7142":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c92f3e1bb0f47d993da0be07cda85a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d9fd1fe88e24eb3815237713cc07f5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7db60b3d04ed4302be036431f8492d6f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e6b457062bf43e0b6184ae09ae1f2fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d72c1bf3cef44abe81ea30aa88ef7cbb","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa675313c2cc4898801c46339ff8eda6","value":2000}},"7e913b671df6492383acefc1acbf5ba2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f8f790bded14024b1988c06de897614":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d773e854a9ba4af4ac2a6d15346fa5f5","placeholder":"​","style":"IPY_MODEL_82a78cbcedde447ea2022aeaddb5bc28","value":"Generating test split: 100%"}},"818a17048f394809aace5d7000887752":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81db8ca32a57451b825a6c0c1b9eb732":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"828208fba310434ea6156500d98c47d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82a78cbcedde447ea2022aeaddb5bc28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82d3fe5bec4a4dd68372339324eb95eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a2bc9c7374b427aa36809e1b4b2e2c5","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5e6a8d8a1a84a14ac645e2f985b0c3a","value":231508}},"8560bee85b904b1d8f598f61457370c8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"867cf3f6144e496b89748bc2bd7b074b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88e5a73c6a7b4362be1fc8da7011b430":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ac8343898934417b6c18290f940e556":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4553ff3aa4c94601b5bd5557bb18012b","IPY_MODEL_bce2dca539a34582a7164f2de8221fe4","IPY_MODEL_1c5f32f73fc9448183d4ea79d0eb57ea"],"layout":"IPY_MODEL_c167c6c9d4044c94838123e21d36d854"}},"8c50d564862043bcbbfb2ff92b876c14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"902747af7bf640bc9a312b4252a469fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91a47c5a2d8542febf579b3f11fe4b9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"945ee263eb264b67971c754c344672f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96a20b625667406a8143481c708f3100":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7e17ce4e57a496ab60856daf362adc3","placeholder":"​","style":"IPY_MODEL_06ed37e0be254c0189af075e6e943c0e","value":"config.json: 100%"}},"96bfe5d6c1c7483689e9144d5d2509db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96e2f4cbb1104355a29813f7b7757bd9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9785e6f541874963bd668717cfcc64b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5030fbf9fbd4266a3697bdc5e13425b","placeholder":"​","style":"IPY_MODEL_553f67fcb6044edf8365b6e773baf8a3","value":" 2000/2000 [00:00&lt;00:00, 3579.80 examples/s]"}},"996b49e8d8c34a6fbee52f7b5879ab93":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99fc506a10cb4c20bd57a5af81075af0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9af8b6cd14a8485d9852d78d14000a1d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c26dad5f2484e8cae8d02c5a137a3e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9dbdeee9f7c44314b1579b7d48ebab16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1d8f71c066e4071ba3e1108edb5d30b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a29cbb282062498699c6e70101c0aa40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a67ac0e01d754329b14494b0a0d66c68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb07045c3f1f45eb9e2af6e415e00e4c","IPY_MODEL_7e6b457062bf43e0b6184ae09ae1f2fe","IPY_MODEL_9785e6f541874963bd668717cfcc64b7"],"layout":"IPY_MODEL_e1a2b74d86c04f02ab8151811c9cafec"}},"a7419b777291448fa661386430065915":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7b298d3caf34dceab2931479b83c2ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad6ab71f36294ef2b05beeb2d8944726":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b059ae6e0f2b4a57913df840b5963267":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b83e1b9363984881a8a40aa176cb02b9","placeholder":"​","style":"IPY_MODEL_d0031feb222641a38b258f5797d9c300","value":"Generating validation split: 100%"}},"b1606dad0963400cb8c0473e59c9237a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2c0760361b0421da2f9e11927f09961":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6a72d9f634b4da181eba2864317c29b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f8f790bded14024b1988c06de897614","IPY_MODEL_65e6952fd45e4c4f9d688a2e51973b0a","IPY_MODEL_d92e500243cb4ecbbc2914816231f62e"],"layout":"IPY_MODEL_29b7d157f3f245eca4791f37a2fbc873"}},"b831373e115c4d218a8575d96110632e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b83e1b9363984881a8a40aa176cb02b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9aaea30007445d1bb9130c697dc9206":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f56c1ed9b2142ac99fe9c93cf7dfc62","IPY_MODEL_4d998081ed04452c91ca7cf72034aefd","IPY_MODEL_41ea4b64b50d4265a931732e773f1b0d"],"layout":"IPY_MODEL_a7419b777291448fa661386430065915"}},"ba75544ff26143b7aa0d06009b40eac9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bce2dca539a34582a7164f2de8221fe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e53372319eb14ca4aa20034bcc724fa4","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d999860389b74db59ba4a5f902ab7653","value":267954768}},"bf4e5535dc19423fb46e54c6db1bc2e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1c6f0e5be2514066a7e89129b220872d","IPY_MODEL_cfad5f4486a241cf9b33f788cfcc85b4","IPY_MODEL_e7466c056232410b8491fc481e10d5a5"],"layout":"IPY_MODEL_c0a25c1bd6fb4a37ad04ddd47878b0fb"}},"c0a25c1bd6fb4a37ad04ddd47878b0fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c167c6c9d4044c94838123e21d36d854":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2e4eaabb8234e84a179ed755f0dcb79":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4553e8d6d174ec199da4f40ca6c6213":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c561d5fab6904adb9db1d92e3f8baa73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c76619126ff14ba3b42a4dc0b38976e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b3febbecfad420db7dd08bca8e05e3a","IPY_MODEL_ed3152d235ec4d4b974ee394d17c73d0","IPY_MODEL_6f6ab1c34c014e64914ce51118952459"],"layout":"IPY_MODEL_1cdb7122235a4c778c063657381c5d74"}},"c7e17ce4e57a496ab60856daf362adc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c81b239d3a3e4640b3de9729bd398c9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c844aa6328cc44f9b5d80a265c390abf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c89f3099e5ba473e8dd9678678c1f45c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8ad2bd72a2b4030a47d2acebf67f4e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbc4693292bc460a81dfb36ab29227a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12b4d4ffc36545c1a07855ea78c28395","placeholder":"​","style":"IPY_MODEL_324291ee005648ceb01e72bd0533c404","value":"split/test-00000-of-00001.parquet: 100%"}},"cc2f29133a8d4924a27d0ef798831e9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"cc4d64e7a7084064a1ed92dcb3b80b38":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd3e423a32a242c5b33b5ccf13e69567":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad6ab71f36294ef2b05beeb2d8944726","max":3000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_728fbe0c1c694361a9a3f206916fc94c","value":3000}},"ce191357312f4804b51cc602d086894d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfad5f4486a241cf9b33f788cfcc85b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_159eb7b4b5f044449a6200b2f3d705ab","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d9fd1fe88e24eb3815237713cc07f5b","value":466062}},"cff260a27080450e956dd5a025aa7ff7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0031feb222641a38b258f5797d9c300":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d11bf26044134d699ab7d4bd6e05f888":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99fc506a10cb4c20bd57a5af81075af0","placeholder":"​","style":"IPY_MODEL_df7a3babb5704b13b089f90585a5cdc5","value":" 127k/127k [00:01&lt;00:00, 80.5kB/s]"}},"d2cf5de4bba54b9cb2d286b7b7843cd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d53150fb5b594fedb37d0e7cfa98f4b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d72c1bf3cef44abe81ea30aa88ef7cbb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d773e854a9ba4af4ac2a6d15346fa5f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d90ac0ef69f342439fe7fa7e929d7164":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d92e500243cb4ecbbc2914816231f62e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2cf5de4bba54b9cb2d286b7b7843cd5","placeholder":"​","style":"IPY_MODEL_828208fba310434ea6156500d98c47d2","value":" 2000/2000 [00:00&lt;00:00, 83544.38 examples/s]"}},"d999860389b74db59ba4a5f902ab7653":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db73a479e8814d03b51e0d1ab767bb87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cff260a27080450e956dd5a025aa7ff7","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d90ac0ef69f342439fe7fa7e929d7164","value":2000}},"dd7eafcdef634698a63dccf812ebe293":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df7a3babb5704b13b089f90585a5cdc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1a2b74d86c04f02ab8151811c9cafec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e46cf2250ea74824b9507a35fdea8686":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0898ea20ddf946acbc754ca6decbaf0c","placeholder":"​","style":"IPY_MODEL_5928e138001749e8a1bf2846cc35c1bc","value":" 129k/129k [00:00&lt;00:00, 476kB/s]"}},"e4cd61e0491c4388aaebef029432315f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e29fdf7446444d4b1f850c077be3d53","IPY_MODEL_07a2d020c1b24bfb84a9505034b11c97","IPY_MODEL_454f27f6c02f41928434c6073e2739ef"],"layout":"IPY_MODEL_b831373e115c4d218a8575d96110632e"}},"e5030fbf9fbd4266a3697bdc5e13425b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e53372319eb14ca4aa20034bcc724fa4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7466c056232410b8491fc481e10d5a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50a5a0d019534a779d8228e477efb919","placeholder":"​","style":"IPY_MODEL_ed97f5c92bf240ef8dd23d65ad16fd87","value":" 466k/466k [00:00&lt;00:00, 7.30MB/s]"}},"e844fceae052449d97b63b39ed2b9a58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e883cdefc0a240b68d1dcf5b2c599293":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d9c3a693964d9bb6f1572bc03c770a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb07045c3f1f45eb9e2af6e415e00e4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba75544ff26143b7aa0d06009b40eac9","placeholder":"​","style":"IPY_MODEL_5886ae8327044265ba840f04ca93064e","value":"Map: 100%"}},"ed3152d235ec4d4b974ee394d17c73d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc2f29133a8d4924a27d0ef798831e9c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0b993e16b7504a7b9e1a67352c1d987f","value":1}},"ed95141e71b648eda10476c71bf90e08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed97f5c92bf240ef8dd23d65ad16fd87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5e6a8d8a1a84a14ac645e2f985b0c3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7a33881311243389b35ca2aa42f7e27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76c72810e7124c1c8c48cd9df89a972b","IPY_MODEL_06af3150a7314a259d247dda4b878f70","IPY_MODEL_d11bf26044134d699ab7d4bd6e05f888"],"layout":"IPY_MODEL_28034f6e8ae345c3a0d37354a74addd1"}},"f9a5a93cd9a645a0837ec5cd5643b013":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa675313c2cc4898801c46339ff8eda6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U 'tensorflow[and-cuda]'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:02:09.493951Z","iopub.execute_input":"2025-11-29T00:02:09.494587Z","iopub.status.idle":"2025-11-29T00:03:21.109849Z","shell.execute_reply.started":"2025-11-29T00:02:09.494554Z","shell.execute_reply":"2025-11-29T00:03:21.109148Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.11/dist-packages (2.18.0)\nCollecting tensorflow[and-cuda]\n  Downloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.6.0)\nRequirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (18.1.1)\nRequirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (25.0)\nRequirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (6.33.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (2.32.5)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.1.0)\nRequirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (4.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.74.0)\nCollecting tensorboard~=2.20.0 (from tensorflow[and-cuda])\n  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting keras>=3.10.0 (from tensorflow[and-cuda])\n  Downloading keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (3.14.0)\nCollecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow[and-cuda])\n  Downloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\nRequirement already satisfied: nvidia-cublas-cu12<13.0,>=12.5.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.3.2)\nRequirement already satisfied: nvidia-cuda-cupti-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: nvidia-cuda-runtime-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.3.0.75 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (9.3.0.75)\nRequirement already satisfied: nvidia-cufft-cu12<12.0,>=11.2.3.61 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.2.3.61)\nRequirement already satisfied: nvidia-curand-cu12<11.0,>=10.3.6.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (10.3.6.82)\nRequirement already satisfied: nvidia-cusolver-cu12<12.0,>=11.6.3.83 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (11.6.3.83)\nRequirement already satisfied: nvidia-cusparse-cu12<13.0,>=12.5.1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.1.3)\nCollecting nvidia-nccl-cu12<3.0,>=2.25.1 (from tensorflow[and-cuda])\n  Downloading nvidia_nccl_cu12-2.28.9-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\nRequirement already satisfied: nvidia-nvjitlink-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.11/dist-packages (from tensorflow[and-cuda]) (12.5.82)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow[and-cuda]) (14.2.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.1.0)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.16.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.0->tensorflow[and-cuda]) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2025.10.5)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.8.2)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (11.3.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow[and-cuda]) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.0->tensorflow[and-cuda]) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.0->tensorflow[and-cuda]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.0->tensorflow[and-cuda]) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.0->tensorflow[and-cuda]) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.0->tensorflow[and-cuda]) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (2.19.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.0->tensorflow[and-cuda]) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow[and-cuda]) (0.1.2)\nDownloading keras-3.12.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ml_dtypes-0.5.4-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.28.9-py3-none-manylinux_2_18_x86_64.whl (296.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.8/296.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.6/620.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, ml_dtypes, tensorboard, keras, tensorflow\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: ml_dtypes\n    Found existing installation: ml-dtypes 0.4.1\n    Uninstalling ml-dtypes-0.4.1:\n      Successfully uninstalled ml-dtypes-0.4.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.18.0\n    Uninstalling tensorboard-2.18.0:\n      Successfully uninstalled tensorboard-2.18.0\n  Attempting uninstall: keras\n    Found existing installation: keras 3.8.0\n    Uninstalling keras-3.8.0:\n      Successfully uninstalled keras-3.8.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.18.0\n    Uninstalling tensorflow-2.18.0:\n      Successfully uninstalled tensorflow-2.18.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.28.9 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ntf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.20.0 which is incompatible.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.20.0 which is incompatible.\ntensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-3.12.0 ml_dtypes-0.5.4 nvidia-nccl-cu12-2.28.9 tensorboard-2.20.0 tensorflow-2.20.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install evaluate","metadata":{"id":"QBTSK7foyxo_","outputId":"c2d0d0a5-f25d-43e0-96e1-54a4210b726f","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:21.111298Z","iopub.execute_input":"2025-11-29T00:03:21.111587Z","iopub.status.idle":"2025-11-29T00:03:32.463507Z","shell.execute_reply.started":"2025-11-29T00:03:21.111563Z","shell.execute_reply":"2025-11-29T00:03:32.462620Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\nCollecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# **1.   Imports**","metadata":{"id":"G0uMRFlq4QSo"}},{"cell_type":"code","source":"import torch\nimport gc\nimport random\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport evaluate\nimport time\nimport glob\nimport ast\n\nfrom typing import Dict, Any, List, Optional, Tuple, cast\nfrom dataclasses import dataclass, asdict\n\n# Hugging Face Libraries\nfrom datasets import load_dataset, DatasetDict\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding,\n    EvalPrediction\n)\nfrom peft import LoraConfig, TaskType, get_peft_model","metadata":{"id":"FaO5xsPcyQBa","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:32.464637Z","iopub.execute_input":"2025-11-29T00:03:32.464932Z","iopub.status.idle":"2025-11-29T00:03:53.028423Z","shell.execute_reply.started":"2025-11-29T00:03:32.464897Z","shell.execute_reply":"2025-11-29T00:03:53.027680Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Hardware & Reproducibility\nSEED = 42\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"id":"tWOPO2zb0b-0","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:53.029257Z","iopub.execute_input":"2025-11-29T00:03:53.029941Z","iopub.status.idle":"2025-11-29T00:03:53.033863Z","shell.execute_reply.started":"2025-11-29T00:03:53.029911Z","shell.execute_reply":"2025-11-29T00:03:53.032637Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Data & Model Settings\nMODEL_NAME = \"distilbert-base-uncased\"\nTRAIN_SAMPLE_SIZE = 3000\nNUM_LABELS = 6\nMAX_LENGTH = 128","metadata":{"id":"Saoe4Phv0jHE","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:53.036545Z","iopub.execute_input":"2025-11-29T00:03:53.037364Z","iopub.status.idle":"2025-11-29T00:03:53.102463Z","shell.execute_reply.started":"2025-11-29T00:03:53.037345Z","shell.execute_reply":"2025-11-29T00:03:53.101632Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# PSO Settings\nPSO_POPULATION_SIZE = 20   # Number of particles\nPSO_EPOCHS = 5            # Number of iterations\nINERTIA_W = 0.7           # Inertia weight\nCOGNITIVE_C1 = 1.5        # Personal best weight\nSOCIAL_C2 = 1.5           # Global best weight","metadata":{"id":"5tBfZqXm0lDC","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:53.103267Z","iopub.execute_input":"2025-11-29T00:03:53.103543Z","iopub.status.idle":"2025-11-29T00:03:53.116405Z","shell.execute_reply.started":"2025-11-29T00:03:53.103518Z","shell.execute_reply":"2025-11-29T00:03:53.115606Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Search Space (Discrete Options)\nWARMUP_OPTIONS = [0.0, 0.06, 0.1]\nRANK_OPTIONS = [2, 4, 8, 16, 24]\nALPHA_OPTIONS = [8, 16, 32, 64, 96]\nDROPOUT_OPTIONS = [0.0, 0.05, 0.1, 0.2]\nTARGET_MODULE_OPTIONS = [\n    [\"q_lin\", \"v_lin\"],                           # Index 0\n    [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]    # Index 1\n]","metadata":{"id":"8mgKBVUk0nuD","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:53.117259Z","iopub.execute_input":"2025-11-29T00:03:53.117535Z","iopub.status.idle":"2025-11-29T00:03:53.130461Z","shell.execute_reply.started":"2025-11-29T00:03:53.117511Z","shell.execute_reply":"2025-11-29T00:03:53.129797Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# **2.   Data Structure Definitions**","metadata":{"id":"6Ux8mVfc5M6U"}},{"cell_type":"code","source":"@dataclass(frozen=True)\nclass LoraHyperparameters:\n    \"\"\"Structure to hold a specific set of hyperparameters\"\"\"\n    learning_rate: float\n    warmup_ratio: float\n    rank: int\n    alpha: int\n    dropout: float\n    target_modules: List[str]\n\nclass Particle:\n    \"\"\"Represents a single particle in the swarm\"\"\"\n    def __init__(self, dim, min_bound, max_bound):\n        self.position = np.random.uniform(min_bound, max_bound, dim)\n        self.velocity = np.random.uniform(-1, 1, dim)\n        self.best_position = np.copy(self.position)\n        self.best_score = -float('inf') # Maximizing accuracy","metadata":{"id":"JXtyXE7V0p0C","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:53.131250Z","iopub.execute_input":"2025-11-29T00:03:53.131990Z","iopub.status.idle":"2025-11-29T00:03:53.145447Z","shell.execute_reply.started":"2025-11-29T00:03:53.131955Z","shell.execute_reply":"2025-11-29T00:03:53.144713Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# **3.   Helper Functions**","metadata":{"id":"DmociEDp5RZl"}},{"cell_type":"code","source":"def set_global_seed(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n\ndef cleanup_memory():\n    \"\"\"Forcefully releases GPU memory\"\"\"\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"id":"IgvJdUZm0uN5","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:53.146269Z","iopub.execute_input":"2025-11-29T00:03:53.146556Z","iopub.status.idle":"2025-11-29T00:03:53.161648Z","shell.execute_reply.started":"2025-11-29T00:03:53.146534Z","shell.execute_reply":"2025-11-29T00:03:53.160883Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# **4.   Data Management Loss**","metadata":{"id":"GAft_wnH666f"}},{"cell_type":"code","source":"class DataManager:\n    def __init__(self, model_name: str = MODEL_NAME):\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.dataset: Optional[Dict[str, Any]] = None\n\n    def prepare_data(self) -> Dict[str, Any]:\n        if self.dataset is not None:\n            return self.dataset\n\n        print(\"Loading and processing data...\")\n        full_dataset = cast(DatasetDict, load_dataset(\"dair-ai/emotion\"))\n\n        # Consistent subset selection\n        train_subset = full_dataset[\"train\"].shuffle(seed=SEED).select(range(TRAIN_SAMPLE_SIZE))\n\n        def _tokenize(examples):\n            return self.tokenizer(\n                examples[\"text\"],\n                truncation=True,\n                padding=\"max_length\",\n                max_length=MAX_LENGTH\n            )\n\n        tokenized_train = train_subset.map(_tokenize, batched=True)\n        tokenized_val = full_dataset[\"validation\"].map(_tokenize, batched=True)\n\n        self.dataset = {\n            \"train\": tokenized_train,\n            \"validation\": tokenized_val,\n            \"tokenizer\": self.tokenizer,\n            \"num_labels\": NUM_LABELS\n        }\n        print(\"Data preparation complete.\")\n        return self.dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:53.162467Z","iopub.execute_input":"2025-11-29T00:03:53.162865Z","iopub.status.idle":"2025-11-29T00:03:53.179833Z","shell.execute_reply.started":"2025-11-29T00:03:53.162837Z","shell.execute_reply":"2025-11-29T00:03:53.179012Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# **5.   PSO Optimiser Engine**","metadata":{"id":"rtyP7dZd7Atx"}},{"cell_type":"code","source":"class PSO_HyperparameterOptimizer:\n    def __init__(self, data_bundle: Dict[str, Any]):\n        self.data = data_bundle\n        self.results: List[Dict[str, Any]] = []\n        self.metric = evaluate.load(\"accuracy\")\n\n        # 6 Dimensions: [LR, Warmup, Rank, Alpha, Dropout, Modules]\n        # We use indices for discrete lists, continuous for LR\n        self.min_bounds = np.array([1e-5, 0, 0, 0, 0, 0], dtype=float)\n        self.max_bounds = np.array([\n            2e-4,\n            len(WARMUP_OPTIONS) - 0.01,\n            len(RANK_OPTIONS) - 0.01,\n            len(ALPHA_OPTIONS) - 0.01,\n            len(DROPOUT_OPTIONS) - 0.01,\n            len(TARGET_MODULE_OPTIONS) - 0.01\n        ], dtype=float)\n        self.dim = 6\n        self.best_params = None\n        self.best_val_accuracy = -1.0\n        self.final_results = [] # Store final results for plotting\n\n    def _map_position_to_params(self, position: np.ndarray) -> LoraHyperparameters:\n        \"\"\"Maps continuous particle position to discrete hyperparameters\"\"\"\n        # Clip to ensure bounds\n        pos = np.clip(position, self.min_bounds, self.max_bounds)\n        return LoraHyperparameters(\n            learning_rate=float(pos[0]),\n            warmup_ratio=WARMUP_OPTIONS[int(pos[1])],\n            rank=RANK_OPTIONS[int(pos[2])],\n            alpha=ALPHA_OPTIONS[int(pos[3])],\n            dropout=DROPOUT_OPTIONS[int(pos[4])],\n            target_modules=TARGET_MODULE_OPTIONS[int(pos[5])]\n        )\n\n    def _compute_metrics(self, eval_pred: EvalPrediction):\n        preds, labels = eval_pred\n        preds = np.argmax(preds, axis=1)\n        return self.metric.compute(predictions=preds, references=labels)\n\n    def train_model(self, trial_id: int, params: LoraHyperparameters) -> float:\n        \"\"\"Runs a single training trial\"\"\"\n        print(f\"   > Params: LR={params.learning_rate:.2e}, Rank={params.rank}, Alpha={params.alpha}\")\n        \n        model = AutoModelForSequenceClassification.from_pretrained(\n            MODEL_NAME, num_labels=self.data[\"num_labels\"]\n        )\n\n        peft_config = LoraConfig(\n            task_type=TaskType.SEQ_CLS,\n            r=params.rank,\n            lora_alpha=params.alpha,\n            lora_dropout=params.dropout,\n            target_modules=params.target_modules\n        )\n        model = get_peft_model(model, peft_config)\n\n        current_seed = SEED + trial_id\n        \n        args = TrainingArguments(\n            output_dir=f\"./results/trial_{trial_id}\",\n            learning_rate=params.learning_rate,\n            per_device_train_batch_size=16,\n            per_device_eval_batch_size=16,\n            num_train_epochs=3,\n            warmup_ratio=params.warmup_ratio,\n            weight_decay=0.01,\n            eval_strategy=\"epoch\",\n            save_strategy=\"no\",\n            logging_strategy=\"epoch\",\n            seed=current_seed,\n            report_to=\"none\",\n            load_best_model_at_end=False\n        )\n\n        data_collator = DataCollatorWithPadding(tokenizer=self.data[\"tokenizer\"])\n\n        trainer = Trainer(\n            model=model,\n            args=args,\n            train_dataset=self.data[\"train\"],\n            eval_dataset=self.data[\"validation\"],\n            data_collator=data_collator,\n            compute_metrics=self._compute_metrics\n        )\n        trainer.train()\n        \n        eval_results = trainer.evaluate()\n        log_history = trainer.state.log_history\n        \n        del model\n        del trainer\n        cleanup_memory()\n\n        return eval_results[\"eval_accuracy\"], log_history\n            \n    def run_optimization(self):\n        print(f\"Starting PSO: {PSO_POPULATION_SIZE} particles, {PSO_EPOCHS} epochs.\")\n        swarm = [Particle(self.dim, self.min_bounds, self.max_bounds) for _ in range(PSO_POPULATION_SIZE)]\n        global_best_pos = np.zeros(self.dim)\n        global_best_score = -float('inf')\n        trial_count = 0\n\n        for epoch in range(PSO_EPOCHS):\n            print(f\"\\n=== PSO EPOCH {epoch + 1}/{PSO_EPOCHS} ===\")\n            for i, particle in enumerate(swarm):\n                trial_count += 1\n\n                try:\n                    params = self._map_position_to_params(particle.position)\n                    \n                    accuracy, _ = self.train_model(trial_count, params)\n                    \n                    print(f\"   > [Trial {trial_count}] Accuracy: {accuracy:.4%}\")\n\n                    if accuracy > particle.best_score:\n                        particle.best_score = accuracy\n                        particle.best_position = np.copy(particle.position)\n\n                    if accuracy > global_best_score:\n                        global_best_score = accuracy\n                        global_best_pos = np.copy(particle.position)\n                        print(f\"   >>> New Swarm Best: {accuracy:.4%}\")\n\n                    record = asdict(params)\n                    record.update({\n                        \"trial_id\": trial_count, \n                        \"val_accuracy\": accuracy, \n                        \"pso_epoch\": epoch+1\n                    })\n                    self.results.append(record)\n\n                except Exception as e:\n                    print(f\"!!! ERROR in Trial {trial_count}: {e}\")\n                    cleanup_memory()\n\n            # Update Particles\n            for particle in swarm:\n                r1, r2 = np.random.rand(self.dim), np.random.rand(self.dim)\n                vel_cognitive = COGNITIVE_C1 * r1 * (particle.best_position - particle.position)\n                vel_social = SOCIAL_C2 * r2 * (global_best_pos - particle.position)\n                particle.velocity = (INERTIA_W * particle.velocity) + vel_cognitive + vel_social\n                particle.position += particle.velocity\n                particle.position = np.clip(particle.position, self.min_bounds, self.max_bounds)\n                \n        # Save Initial Results to CSV immediately after loop\n        self.save_results(\"initial_results.csv\")\n\n    def evaluate_top_solutions_with_seeds(self, run_id=1, num_top=5, num_seeds=3):\n        \"\"\"\n        Retrains the top 5 unique configs found in PSO 3 times each with NEW seeds.\n        Calculates Mean, Median, and Std Dev.\n        \"\"\"\n        print(f\"\\n{'='*60}\")\n        print(f\"ROBUSTNESS CHECK: TOP {num_top} CONFIGS x {num_seeds} NEW SEEDS\")\n        print(f\"{'='*60}\")\n\n        # 1. Filter Top Unique Candidates\n        sorted_results = sorted(self.results, key=lambda x: x['val_accuracy'], reverse=True)\n        unique_candidates = []\n        seen_configs = set()\n\n        for res in sorted_results:\n            config_key = (\n                res['learning_rate'], res['warmup_ratio'], res['rank'], \n                res['alpha'], res['dropout'], tuple(res['target_modules'])\n            )\n            if config_key not in seen_configs:\n                seen_configs.add(config_key)\n                unique_candidates.append(res)\n            if len(unique_candidates) >= num_top:\n                break\n\n        self.final_results = []\n        raw_data = []\n        \n        # 2. Retrain Candidates\n        # Renamed loop variable to 'sol_rank' to avoid conflict with LoRA 'rank' parameter\n        for sol_rank, candidate in enumerate(unique_candidates, 1):\n            params = LoraHyperparameters(\n                learning_rate=candidate['learning_rate'],\n                warmup_ratio=candidate['warmup_ratio'],\n                rank=candidate['rank'],\n                alpha=candidate['alpha'],\n                dropout=candidate['dropout'],\n                target_modules=candidate['target_modules']\n            )\n\n            print(f\"\\n--- Solution Rank {sol_rank} (Original Acc: {candidate['val_accuracy']:.4%}) ---\")\n            seed_accuracies = []\n            #seed_histories = []\n\n            for seed_i in range(num_seeds):\n                robust_trial_id = 10000 + (run_id * 100) + seed_i\n                display_seed = SEED + robust_trial_id\n                \n                print(f\"   > Retraining Seed {seed_i + 1}/{num_seeds} (Seed: {display_seed})...\", end=\" \", flush=True)\n                \n                acc, _ = self.train_model(robust_trial_id, params)\n                \n                seed_accuracies.append(acc)\n                print(f\"Acc: {acc:.4%}\")\n                \n                raw_record = asdict(params)\n                raw_record.update({\n                    \"candidate_rank\": sol_rank,\n                    \"seed_index\": seed_i + 1,\n                    \"trial_id\": robust_trial_id,\n                    \"val_accuracy\": acc,\n                    \"original_pso_accuracy\": candidate['val_accuracy']\n                })\n                raw_data.append(raw_record)\n\n            # --- Calculate Statistics ---\n            mean_acc = np.mean(seed_accuracies)\n            std_acc = np.std(seed_accuracies)\n\n            print(f\"   >>> Stats | Mean Acc: {mean_acc:.4%} | Std: {std_acc:.4f}\")\n            \n            # Prepare Record\n            # asdict(params) contains keys like 'learning_rate', 'rank', etc.\n            record = asdict(params) \n            record.update({\n                'solution_rank': sol_rank,\n                'original_pso_accuracy': candidate['val_accuracy'],\n                'mean_robust_accuracy': mean_acc,\n                'std_robust_accuracy': std_acc,\n                'seed_accuracies': str(seed_accuracies)\n            })\n            self.final_results.append(record)\n\n        # 3. Save Results using the helper method\n        robust_filename = f\"robust_results.csv\"\n        self.save_top_solutions_results(self.final_results, robust_filename)\n\n        # 4. Save Raw Trials (The 15 rows file)\n        raw_df = pd.DataFrame(raw_data)\n        raw_df.to_csv(\"robust_trials.csv\", index=False)\n        print(f\"Raw robustness trials saved to robust_trials.csv\")\n        \n        # 5. Update Best Params based on MEAN accuracy (Stability wins)\n        self.final_results.sort(key=lambda x: x['mean_robust_accuracy'], reverse=True)\n        if self.final_results:\n            winner = self.final_results[0]\n            # Print update message (Summary is handled in save_top_solutions_results)\n            print(f\"\\nUpdating Best Params to Solution Rank {winner['solution_rank']}\")\n            \n            self.best_params = LoraHyperparameters(\n                learning_rate=winner['learning_rate'],\n                warmup_ratio=winner['warmup_ratio'],\n                rank=winner['rank'],\n                alpha=winner['alpha'],\n                dropout=winner['dropout'],\n                target_modules=winner['target_modules']\n            )\n            self.best_val_accuracy = winner['mean_robust_accuracy']\n    \n    def save_top_solutions_results(self, final_results, filename: str):\n        \"\"\"\n        Saves results matching the specific CSV format:\n        rank | learning_rate | ... | mean_accuracy | std_accuracy | seed_1 | seed_2 ...\n        \"\"\"\n        if not final_results:\n            print(\"No top solutions results to save.\")\n            return\n        \n        rows = []\n        for result in final_results:\n            # Handle Target Modules\n            t_mods = result.get('target_modules', [])\n            if isinstance(t_mods, str):\n                try: t_mods = ast.literal_eval(t_mods)\n                except: pass\n            \n            target_binary = 0 if len(t_mods) <= 2 else 1\n\n            # Build Row\n            row = {\n                'rank': result.get('solution_rank'),\n                'learning_rate': result.get('learning_rate'),\n                'warmup_ratio': result.get('warmup_ratio'),\n                'rank_r': result.get('rank'),\n                'alpha': result.get('alpha'),\n                'dropout': result.get('dropout'),\n                'target_modules': target_binary,\n                'original_accuracy': result.get('original_pso_accuracy'),\n                'mean_accuracy': result.get('mean_robust_accuracy'),\n                'std_accuracy': result.get('std_robust_accuracy')\n            }\n            \n            # Handle Seed Accuracies\n            seeds = result.get('seed_accuracies', [])\n            if isinstance(seeds, str):\n                try: seeds = ast.literal_eval(seeds)\n                except: seeds = []\n            \n            for i, acc in enumerate(seeds, 1):\n                row[f'seed_{i}_accuracy'] = acc\n            \n            rows.append(row)\n        \n        df = pd.DataFrame(rows)\n        \n        # Enforce Column Order (Median Removed)\n        cols_order = [\n            'rank', 'learning_rate', 'warmup_ratio', 'rank_r', 'alpha', 'dropout', \n            'target_modules', 'original_accuracy', 'mean_accuracy', 'std_accuracy'\n        ]\n        \n        seed_cols = [c for c in df.columns if c.startswith('seed_')]\n        cols_order.extend(sorted(seed_cols))\n        \n        final_cols = [c for c in cols_order if c in df.columns]\n        df = df[final_cols]\n\n        df.to_csv(filename, index=False)\n        print(f\"\\nTop solutions results saved to {filename}\")\n        \n        if not df.empty:\n            best = df.loc[df['mean_accuracy'].idxmax()]\n            print(\"\\n\" + \"=\"*60)\n            print(\"BEST CONFIGURATION (Formatted Output):\")\n            print(\"=\"*60)\n            print(f\"Rank: {best['rank']}\")\n            print(f\"Mean Accuracy: {best['mean_accuracy']:.4%} ± {best['std_accuracy']:.4f}\")\n            print(f\"Params: LR={best['learning_rate']:.2e}, r={best['rank_r']}, alpha={best['alpha']}\")\n            print(\"=\"*60)\n    \n    def save_results(self, filename: str):\n        if not self.results:\n            print(\"No results to save.\")\n            return\n        df = pd.DataFrame(self.results)\n        df.to_csv(filename, index=False)\n        print(f\"Results saved to {filename}\")\n        \n        best_run = df.loc[df['val_accuracy'].idxmax()]\n        print(\"\\nBEST VALIDATION RESULT:\")\n        print(f\"Accuracy: {best_run['val_accuracy']:.4%}\")\n        \n        print(f\"Rank: {best_run['rank']}, Alpha: {best_run['alpha']}, LR: {best_run['learning_rate']:.2e}\")","metadata":{"id":"cqprVCju0zhN","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:53.180801Z","iopub.execute_input":"2025-11-29T00:03:53.181073Z","iopub.status.idle":"2025-11-29T00:03:53.579775Z","shell.execute_reply.started":"2025-11-29T00:03:53.181051Z","shell.execute_reply":"2025-11-29T00:03:53.578957Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# **6.   Main Execution Pipeline**","metadata":{"id":"rq-nEUIT7HL_"}},{"cell_type":"code","source":"def run_single_optimization(run_id: int, data_bundle: Dict[str, Any]) -> Tuple[float, float, LoraHyperparameters, Any]:\n    print(f\"\\n{'='*60}\\nRUN {run_id + 1}\\n{'='*60}\")\n\n    optimizer = PSO_HyperparameterOptimizer(data_bundle)\n\n    start_time = time.time()\n    \n    # 1. Broad Search (20 particles)\n    optimizer.run_optimization()\n\n    end_time = time.time()\n    elapsed_time = (end_time - start_time) / 60 \n    \n    print(\"\\n\" + \"=\"*60)\n    print(f\"ELAPSED TIME: {elapsed_time:.2f} m\")\n    print(\"\\n\" + \"=\"*60)\n    \n    optimizer.evaluate_top_solutions_with_seeds(run_id=run_id, num_top=5, num_seeds=3)\n    \n    # 3. Save PSO History\n    optimizer.save_results(f\"initial_results.csv\")\n    \n    # 4. Final Test\n    print(\"\\n\" + \"=\"*50 + \"\\nEVALUATING ROBUST BEST CONFIG ON TEST SET\\n\" + \"=\"*50)\n    print(f\"\\nRun {run_id + 1} - Robust Val: {optimizer.best_val_accuracy:.4%}\")\n\n    return optimizer.best_val_accuracy, optimizer.best_params, optimizer\n\nif __name__ == \"__main__\":\n    NUM_RUNS = 1  # Number of independent optimization runs\n    STOCHASTICITY_SEED_BASE = SEED\n\n    print(\"=\"*60)\n    print(f\"STOCHASTICITY REPORTING: {NUM_RUNS} FULL OPTIMIZATION RUN\")\n    print(\"=\"*60)\n\n    all_results = []\n    val_accuracies = []\n\n    optimizer = None\n\n    try:\n        # 1. Prepare Data (once, reused for all runs)\n        data_mgr = DataManager(MODEL_NAME)\n        data_bundle = data_mgr.prepare_data()\n\n        for run in range(NUM_RUNS):\n            set_global_seed(STOCHASTICITY_SEED_BASE + run)\n\n            try:\n                val_acc, best_params, optimizer = run_single_optimization(run, data_bundle)\n\n                all_results.append({\n                    \"run_id\": run + 1,\n                    \"seed\": STOCHASTICITY_SEED_BASE + run,\n                    \"val_accuracy\": val_acc,\n                    \"learning_rate\": best_params.learning_rate,\n                    \"warmup_ratio\": best_params.warmup_ratio,\n                    \"rank\": best_params.rank,\n                    \"alpha\": best_params.alpha,\n                    \"dropout\": best_params.dropout,\n                    \"target_modules\": str(best_params.target_modules)\n                })\n\n                val_accuracies.append(val_acc)\n                \n            except Exception as e:\n                print(f\"!!! ERROR in Run {run + 1}: {e}\")\n                import traceback\n                traceback.print_exc()\n                cleanup_memory()\n\n        # 3. Print Summary Statistics\n        print(\"\\n\" + \"=\"*60)\n        print(\"STOCHASTICITY SUMMARY\")\n        print(\"=\"*60)\n\n        if val_accuracies:\n            val_mean = np.mean(val_accuracies)\n            val_std = np.std(val_accuracies)\n            val_min = np.min(val_accuracies)\n            val_max = np.max(val_accuracies)\n\n            print(f\"\\nVALIDATION ACCURACY (from PSO search):\")\n            print(f\"  Mean: {val_mean:.4%}\")\n            print(f\"  Std:  {val_std:.4%}\")\n            print(f\"  Min:  {val_min:.4%}\")\n            print(f\"  Max:  {val_max:.4%}\")\n\n            print(f\"\\nIndividual Results:\")\n            for result in all_results:\n                print(f\"  Run {result['run_id']}: Val={result['val_accuracy']:.4%}\")\n\n        # 4. Save stochasticity results\n        results_df = pd.DataFrame(all_results)\n        results_df.to_csv(\"pso_stochasticity_results.csv\", index=False)\n        print(f\"\\nStochasticity results saved to pso_stochasticity_results.csv\")\n\n        # Print Final Summary\n        print(\"\\n\" + \"=\"*60)\n        print(\"FINAL SINGLE RUN SUMMARY\")\n        print(\"=\"*60)\n        \n        if all_results:\n            res = all_results[0]\n            print(f\"Run 1 Results:\")\n            print(f\"  Robust Validation Accuracy: {res['val_accuracy']:.4%}\")\n            print(f\"  Best Parameters Found:\")\n            print(f\"    LR: {res['learning_rate']:.2e}, Rank: {res['rank']}, Alpha: {res['alpha']}\")\n\n        # 4. Save results\n        results_df = pd.DataFrame(all_results)\n        results_df.to_csv(\"pso_final_results.csv\", index=False)\n        print(f\"\\nFinal results saved to pso_final_results.csv\")\n    \n    except KeyboardInterrupt:\n        print(\"\\nOptimization interrupted by user.\")\n    except Exception as e:\n        print(f\"\\nCritical failure: {e}\")\n        import traceback\n        traceback.print_exc()\n    finally:\n        # Always save whatever results we have\n        if optimizer is not None:\n            print(\"Executing emergency save...\")\n            optimizer.save_results(\"pso_optimization_results.csv\")\n            \n            if hasattr(optimizer, 'final_results') and optimizer.final_results:\n                optimizer.save_top_solutions_results(\n                    optimizer.final_results,\n                    \"pso_top_solutions_multiseed.csv\"\n                )\n        cleanup_memory()\n        print(\"Process Complete.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T00:03:53.580624Z","iopub.execute_input":"2025-11-29T00:03:53.580965Z","iopub.status.idle":"2025-11-29T02:08:59.383804Z","shell.execute_reply.started":"2025-11-29T00:03:53.580939Z","shell.execute_reply":"2025-11-29T02:08:59.382683Z"}},"outputs":[{"name":"stdout","text":"============================================================\nSTOCHASTICITY REPORTING: 1 FULL OPTIMIZATION RUN\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33e77827f573471c8a6e6f622693ddf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90dc15a1c6a24171b5c1d4c5b68c5f39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cabe204af10d4189af2d40754b9e474b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fe29a8401924adfa21b595d5b291e0a"}},"metadata":{}},{"name":"stdout","text":"Loading and processing data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"496fe872d772434bad8bbca954cbb893"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"split/train-00000-of-00001.parquet:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffd31eccb1154d4b95c415e6bf677c64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"split/validation-00000-of-00001.parquet:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a285b694ebf4a5c87810736ede63a8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"split/test-00000-of-00001.parquet:   0%|          | 0.00/129k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b93035b61ac425891c59a07aeac1edf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baa64a17fff64b82bc6cbe6f3d6816e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"583741d963e24430a530a8c6736d10f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f9924507ed04e9c87cb8b0407e6a149"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b8db276780145cf9c18475414df4626"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d26a01e7f2d4eabadac6c6ecd030778"}},"metadata":{}},{"name":"stdout","text":"Data preparation complete.\n\n============================================================\nRUN 1\n============================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d944c153e09468181e3bc4a028ea63a"}},"metadata":{}},{"name":"stdout","text":"Starting PSO: 20 particles, 5 epochs.\n\n=== PSO EPOCH 1/5 ===\n   > Params: LR=8.12e-05, Rank=16, Alpha=32\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfc11e58e7b24ffcaeb0b11c8dc8fd71"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.444800</td>\n      <td>1.088532</td>\n      <td>0.605000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.916800</td>\n      <td>0.811604</td>\n      <td>0.693500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.753100</td>\n      <td>0.756660</td>\n      <td>0.719500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 1] Accuracy: 71.9500%\n   >>> New Swarm Best: 71.9500%\n   > Params: LR=1.68e-04, Rank=2, Alpha=8\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.213800</td>\n      <td>0.856150</td>\n      <td>0.679000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.699900</td>\n      <td>0.600882</td>\n      <td>0.773000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.546200</td>\n      <td>0.550887</td>\n      <td>0.800500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 2] Accuracy: 80.0500%\n   >>> New Swarm Best: 80.0500%\n   > Params: LR=9.67e-05, Rank=2, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.381500</td>\n      <td>1.023578</td>\n      <td>0.632500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.887100</td>\n      <td>0.812718</td>\n      <td>0.694000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.754500</td>\n      <td>0.764119</td>\n      <td>0.715500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 3] Accuracy: 71.5500%\n   > Params: LR=6.79e-05, Rank=16, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.411100</td>\n      <td>1.126337</td>\n      <td>0.591000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.002600</td>\n      <td>0.910215</td>\n      <td>0.671000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.862400</td>\n      <td>0.860365</td>\n      <td>0.684000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 4] Accuracy: 68.4000%\n   > Params: LR=1.14e-04, Rank=24, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.131300</td>\n      <td>0.738939</td>\n      <td>0.714500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.568300</td>\n      <td>0.475259</td>\n      <td>0.834000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.391200</td>\n      <td>0.434376</td>\n      <td>0.845500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 5] Accuracy: 84.5500%\n   >>> New Swarm Best: 84.5500%\n   > Params: LR=8.38e-05, Rank=24, Alpha=16\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.313900</td>\n      <td>0.975560</td>\n      <td>0.644000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.826400</td>\n      <td>0.731129</td>\n      <td>0.728000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.661100</td>\n      <td>0.667505</td>\n      <td>0.751000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 6] Accuracy: 75.1000%\n   > Params: LR=1.10e-05, Rank=16, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.671000</td>\n      <td>1.572933</td>\n      <td>0.352000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.531300</td>\n      <td>1.509433</td>\n      <td>0.478500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.473200</td>\n      <td>1.470748</td>\n      <td>0.509000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 7] Accuracy: 50.9000%\n   > Params: LR=6.91e-05, Rank=16, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.385100</td>\n      <td>1.073283</td>\n      <td>0.626000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.935000</td>\n      <td>0.846481</td>\n      <td>0.692000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.787500</td>\n      <td>0.792928</td>\n      <td>0.703000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 8] Accuracy: 70.3000%\n   > Params: LR=1.09e-04, Rank=2, Alpha=8\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.338000</td>\n      <td>1.002991</td>\n      <td>0.632500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.835100</td>\n      <td>0.738651</td>\n      <td>0.717500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.665100</td>\n      <td>0.683967</td>\n      <td>0.746000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 9] Accuracy: 74.6000%\n   > Params: LR=5.35e-05, Rank=4, Alpha=8\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.497900</td>\n      <td>1.254596</td>\n      <td>0.541000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.136100</td>\n      <td>1.066274</td>\n      <td>0.607500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.008800</td>\n      <td>1.005839</td>\n      <td>0.637000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 10] Accuracy: 63.7000%\n   > Params: LR=1.63e-04, Rank=4, Alpha=8\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.376300</td>\n      <td>0.979669</td>\n      <td>0.646000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.813500</td>\n      <td>0.714620</td>\n      <td>0.731500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.668000</td>\n      <td>0.671446</td>\n      <td>0.757000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 11] Accuracy: 75.7000%\n   > Params: LR=3.28e-05, Rank=24, Alpha=16\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.560200</td>\n      <td>1.326441</td>\n      <td>0.531500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.182400</td>\n      <td>1.120180</td>\n      <td>0.589500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.074500</td>\n      <td>1.066958</td>\n      <td>0.604000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 12] Accuracy: 60.4000%\n   > Params: LR=6.41e-05, Rank=16, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.415700</td>\n      <td>1.160843</td>\n      <td>0.561000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.020500</td>\n      <td>0.934840</td>\n      <td>0.660000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.879100</td>\n      <td>0.875575</td>\n      <td>0.681000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 13] Accuracy: 68.1000%\n   > Params: LR=1.38e-04, Rank=4, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.180800</td>\n      <td>0.711600</td>\n      <td>0.728000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.557500</td>\n      <td>0.479855</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.366800</td>\n      <td>0.409988</td>\n      <td>0.861000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 14] Accuracy: 86.1000%\n   >>> New Swarm Best: 86.1000%\n   > Params: LR=1.77e-05, Rank=16, Alpha=8\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.641300</td>\n      <td>1.568984</td>\n      <td>0.355500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.541000</td>\n      <td>1.538081</td>\n      <td>0.437000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.514600</td>\n      <td>1.524267</td>\n      <td>0.463000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 15] Accuracy: 46.3000%\n   > Params: LR=7.48e-05, Rank=24, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.173700</td>\n      <td>0.820586</td>\n      <td>0.690000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.642600</td>\n      <td>0.575112</td>\n      <td>0.784500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.471700</td>\n      <td>0.509305</td>\n      <td>0.821500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 16] Accuracy: 82.1500%\n   > Params: LR=1.81e-04, Rank=4, Alpha=16\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.198500</td>\n      <td>0.728205</td>\n      <td>0.721500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.591900</td>\n      <td>0.509762</td>\n      <td>0.814000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.420400</td>\n      <td>0.453531</td>\n      <td>0.835000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 17] Accuracy: 83.5000%\n   > Params: LR=1.25e-04, Rank=2, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.217000</td>\n      <td>0.878435</td>\n      <td>0.682000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.764300</td>\n      <td>0.681147</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.612900</td>\n      <td>0.639759</td>\n      <td>0.762500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 18] Accuracy: 76.2500%\n   > Params: LR=7.18e-05, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.308300</td>\n      <td>0.874820</td>\n      <td>0.698000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.689900</td>\n      <td>0.585055</td>\n      <td>0.788500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.491200</td>\n      <td>0.519369</td>\n      <td>0.819500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 19] Accuracy: 81.9500%\n   > Params: LR=1.79e-04, Rank=16, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.200100</td>\n      <td>0.774163</td>\n      <td>0.712500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.640000</td>\n      <td>0.574911</td>\n      <td>0.788000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.502600</td>\n      <td>0.539769</td>\n      <td>0.805000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 20] Accuracy: 80.5000%\n\n=== PSO EPOCH 2/5 ===\n   > Params: LR=1.00e-05, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.666700</td>\n      <td>1.566462</td>\n      <td>0.352500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.516800</td>\n      <td>1.481088</td>\n      <td>0.512500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.438200</td>\n      <td>1.428573</td>\n      <td>0.526000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 21] Accuracy: 52.6000%\n   > Params: LR=1.00e-05, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.608900</td>\n      <td>1.541677</td>\n      <td>0.453000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.462800</td>\n      <td>1.394927</td>\n      <td>0.530000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.345500</td>\n      <td>1.335709</td>\n      <td>0.540500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 22] Accuracy: 54.0500%\n   > Params: LR=2.00e-04, Rank=2, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.187700</td>\n      <td>0.771031</td>\n      <td>0.713000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.639100</td>\n      <td>0.574484</td>\n      <td>0.801500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.503000</td>\n      <td>0.523596</td>\n      <td>0.806500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 23] Accuracy: 80.6500%\n   > Params: LR=1.00e-05, Rank=4, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.654100</td>\n      <td>1.531317</td>\n      <td>0.465000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.450800</td>\n      <td>1.379525</td>\n      <td>0.536000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.338700</td>\n      <td>1.326609</td>\n      <td>0.541000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 24] Accuracy: 54.1000%\n   > Params: LR=2.00e-04, Rank=2, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.135800</td>\n      <td>0.665872</td>\n      <td>0.763500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.474000</td>\n      <td>0.403197</td>\n      <td>0.862000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.282900</td>\n      <td>0.369653</td>\n      <td>0.876500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 25] Accuracy: 87.6500%\n   >>> New Swarm Best: 87.6500%\n   > Params: LR=1.00e-05, Rank=8, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.686500</td>\n      <td>1.581430</td>\n      <td>0.359000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.541000</td>\n      <td>1.522092</td>\n      <td>0.471500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.492200</td>\n      <td>1.493066</td>\n      <td>0.496000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 26] Accuracy: 49.6000%\n   > Params: LR=1.00e-05, Rank=8, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.677400</td>\n      <td>1.577153</td>\n      <td>0.352500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.538400</td>\n      <td>1.522553</td>\n      <td>0.447000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.493900</td>\n      <td>1.497883</td>\n      <td>0.491000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 27] Accuracy: 49.1000%\n   > Params: LR=1.00e-05, Rank=2, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.658800</td>\n      <td>1.554828</td>\n      <td>0.360000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.502100</td>\n      <td>1.457566</td>\n      <td>0.510500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.417200</td>\n      <td>1.406586</td>\n      <td>0.525500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 28] Accuracy: 52.5500%\n   > Params: LR=1.00e-05, Rank=8, Alpha=16\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.668600</td>\n      <td>1.582281</td>\n      <td>0.437000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.548900</td>\n      <td>1.536602</td>\n      <td>0.472000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.513300</td>\n      <td>1.518212</td>\n      <td>0.477500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 29] Accuracy: 47.7500%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.020200</td>\n      <td>0.537583</td>\n      <td>0.821000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.405700</td>\n      <td>0.365035</td>\n      <td>0.873000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.221100</td>\n      <td>0.332442</td>\n      <td>0.892000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 30] Accuracy: 89.2000%\n   >>> New Swarm Best: 89.2000%\n   > Params: LR=2.00e-04, Rank=2, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.201500</td>\n      <td>0.764347</td>\n      <td>0.713000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.625600</td>\n      <td>0.587063</td>\n      <td>0.782000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.475200</td>\n      <td>0.529532</td>\n      <td>0.816500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 31] Accuracy: 81.6500%\n   > Params: LR=1.00e-05, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.652000</td>\n      <td>1.573035</td>\n      <td>0.354500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.533600</td>\n      <td>1.510710</td>\n      <td>0.473500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.477100</td>\n      <td>1.472645</td>\n      <td>0.508000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 32] Accuracy: 50.8000%\n   > Params: LR=2.00e-04, Rank=4, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.056000</td>\n      <td>0.635647</td>\n      <td>0.774000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.498800</td>\n      <td>0.440053</td>\n      <td>0.846500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.340100</td>\n      <td>0.378565</td>\n      <td>0.878000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 33] Accuracy: 87.8000%\n   > Params: LR=2.00e-04, Rank=2, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.182300</td>\n      <td>0.737700</td>\n      <td>0.713000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.614800</td>\n      <td>0.534552</td>\n      <td>0.810500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.471000</td>\n      <td>0.492276</td>\n      <td>0.820500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 34] Accuracy: 82.0500%\n   > Params: LR=2.00e-04, Rank=8, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.160800</td>\n      <td>0.698873</td>\n      <td>0.755000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.578200</td>\n      <td>0.534174</td>\n      <td>0.813000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.446900</td>\n      <td>0.481324</td>\n      <td>0.827500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   > [Trial 35] Accuracy: 82.7500%\n   > Params: LR=2.00e-04, Rank=2, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.036800</td>\n      <td>0.628432</td>\n      <td>0.791000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.504300</td>\n      <td>0.436089</td>\n      <td>0.854000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.316200</td>\n      <td>0.381507</td>\n      <td>0.870500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 36] Accuracy: 87.0500%\n   > Params: LR=2.00e-04, Rank=4, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.168900</td>\n      <td>0.665701</td>\n      <td>0.754500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.490800</td>\n      <td>0.435696</td>\n      <td>0.855000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.308800</td>\n      <td>0.396725</td>\n      <td>0.870000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 37] Accuracy: 87.0000%\n   > Params: LR=2.00e-04, Rank=4, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.029600</td>\n      <td>0.614067</td>\n      <td>0.781500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.436700</td>\n      <td>0.393677</td>\n      <td>0.870500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.256100</td>\n      <td>0.356116</td>\n      <td>0.889000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 38] Accuracy: 88.9000%\n   > Params: LR=1.00e-05, Rank=2, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.660300</td>\n      <td>1.545273</td>\n      <td>0.459500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.458800</td>\n      <td>1.384829</td>\n      <td>0.537500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.333200</td>\n      <td>1.328059</td>\n      <td>0.545000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 39] Accuracy: 54.5000%\n   > Params: LR=1.00e-05, Rank=4, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.735800</td>\n      <td>1.614096</td>\n      <td>0.352500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.567300</td>\n      <td>1.549607</td>\n      <td>0.416500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.530800</td>\n      <td>1.536434</td>\n      <td>0.457500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 40] Accuracy: 45.7500%\n\n=== PSO EPOCH 3/5 ===\n   > Params: LR=1.00e-05, Rank=8, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.621900</td>\n      <td>1.531509</td>\n      <td>0.454000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.451000</td>\n      <td>1.381325</td>\n      <td>0.529500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.341300</td>\n      <td>1.329660</td>\n      <td>0.539500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 41] Accuracy: 53.9500%\n   > Params: LR=1.00e-05, Rank=8, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.675600</td>\n      <td>1.557915</td>\n      <td>0.364500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.511300</td>\n      <td>1.482717</td>\n      <td>0.492500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.445300</td>\n      <td>1.443139</td>\n      <td>0.522000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 42] Accuracy: 52.2000%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.002200</td>\n      <td>0.582475</td>\n      <td>0.792000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.401100</td>\n      <td>0.388429</td>\n      <td>0.871000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.261000</td>\n      <td>0.354090</td>\n      <td>0.886000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 43] Accuracy: 88.6000%\n   > Params: LR=1.00e-05, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.624800</td>\n      <td>1.525037</td>\n      <td>0.382000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.438100</td>\n      <td>1.359707</td>\n      <td>0.529000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.322200</td>\n      <td>1.310842</td>\n      <td>0.539500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 44] Accuracy: 53.9500%\n   > Params: LR=2.00e-04, Rank=2, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.212800</td>\n      <td>0.775368</td>\n      <td>0.715000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.633900</td>\n      <td>0.572019</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.483900</td>\n      <td>0.507508</td>\n      <td>0.821000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 45] Accuracy: 82.1000%\n   > Params: LR=1.00e-05, Rank=4, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.661900</td>\n      <td>1.550494</td>\n      <td>0.445000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.475000</td>\n      <td>1.409765</td>\n      <td>0.531500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.362700</td>\n      <td>1.350121</td>\n      <td>0.536000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 46] Accuracy: 53.6000%\n   > Params: LR=1.00e-05, Rank=8, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.668200</td>\n      <td>1.548590</td>\n      <td>0.394000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.484900</td>\n      <td>1.421238</td>\n      <td>0.535000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.377100</td>\n      <td>1.360169</td>\n      <td>0.540000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 47] Accuracy: 54.0000%\n   > Params: LR=1.00e-05, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.623800</td>\n      <td>1.476352</td>\n      <td>0.515000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.359200</td>\n      <td>1.285470</td>\n      <td>0.551500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.255800</td>\n      <td>1.243775</td>\n      <td>0.556500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 48] Accuracy: 55.6500%\n   > Params: LR=1.00e-05, Rank=4, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.677900</td>\n      <td>1.570374</td>\n      <td>0.445000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.523200</td>\n      <td>1.494174</td>\n      <td>0.477000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.454000</td>\n      <td>1.448086</td>\n      <td>0.516500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 49] Accuracy: 51.6500%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.023300</td>\n      <td>0.550690</td>\n      <td>0.796500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.407400</td>\n      <td>0.371344</td>\n      <td>0.873000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.220500</td>\n      <td>0.337849</td>\n      <td>0.896500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 50] Accuracy: 89.6500%\n   >>> New Swarm Best: 89.6500%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.052600</td>\n      <td>0.613502</td>\n      <td>0.780000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.434400</td>\n      <td>0.491527</td>\n      <td>0.845500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.274500</td>\n      <td>0.349817</td>\n      <td>0.884500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 51] Accuracy: 88.4500%\n   > Params: LR=1.00e-05, Rank=8, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.667000</td>\n      <td>1.560738</td>\n      <td>0.370000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.523200</td>\n      <td>1.498241</td>\n      <td>0.481500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.464200</td>\n      <td>1.462585</td>\n      <td>0.508000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 52] Accuracy: 50.8000%\n   > Params: LR=2.00e-04, Rank=2, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.055500</td>\n      <td>0.616723</td>\n      <td>0.780500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.442000</td>\n      <td>0.391097</td>\n      <td>0.876000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.266800</td>\n      <td>0.361611</td>\n      <td>0.880500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 53] Accuracy: 88.0500%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.944500</td>\n      <td>0.563043</td>\n      <td>0.800500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.385800</td>\n      <td>0.376915</td>\n      <td>0.881000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.231000</td>\n      <td>0.344715</td>\n      <td>0.892000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 54] Accuracy: 89.2000%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.104800</td>\n      <td>0.615864</td>\n      <td>0.786000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.432900</td>\n      <td>0.375892</td>\n      <td>0.876000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.255600</td>\n      <td>0.347047</td>\n      <td>0.888000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 55] Accuracy: 88.8000%\n   > Params: LR=2.00e-04, Rank=2, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.075200</td>\n      <td>0.610314</td>\n      <td>0.766500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.476000</td>\n      <td>0.445857</td>\n      <td>0.850500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.293700</td>\n      <td>0.358916</td>\n      <td>0.885000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 56] Accuracy: 88.5000%\n   > Params: LR=2.00e-04, Rank=4, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.124600</td>\n      <td>0.630139</td>\n      <td>0.792000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.450100</td>\n      <td>0.407323</td>\n      <td>0.857000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.261100</td>\n      <td>0.363982</td>\n      <td>0.881500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 57] Accuracy: 88.1500%\n   > Params: LR=2.00e-04, Rank=4, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.072500</td>\n      <td>0.655034</td>\n      <td>0.757000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.445800</td>\n      <td>0.375417</td>\n      <td>0.876000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.275000</td>\n      <td>0.348492</td>\n      <td>0.883500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 58] Accuracy: 88.3500%\n   > Params: LR=1.00e-05, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.641200</td>\n      <td>1.502244</td>\n      <td>0.466000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.383700</td>\n      <td>1.294115</td>\n      <td>0.549500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.262100</td>\n      <td>1.252592</td>\n      <td>0.556000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 59] Accuracy: 55.6000%\n   > Params: LR=1.00e-05, Rank=4, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.639900</td>\n      <td>1.545056</td>\n      <td>0.379500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.480500</td>\n      <td>1.420812</td>\n      <td>0.528000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.377400</td>\n      <td>1.364637</td>\n      <td>0.534000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 60] Accuracy: 53.4000%\n\n=== PSO EPOCH 4/5 ===\n   > Params: LR=1.00e-05, Rank=8, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.653500</td>\n      <td>1.573117</td>\n      <td>0.353000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.537900</td>\n      <td>1.526511</td>\n      <td>0.430000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.502600</td>\n      <td>1.503606</td>\n      <td>0.473000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 61] Accuracy: 47.3000%\n   > Params: LR=1.00e-05, Rank=4, Alpha=8\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.686400</td>\n      <td>1.601241</td>\n      <td>0.352000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.569300</td>\n      <td>1.558463</td>\n      <td>0.366500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.539800</td>\n      <td>1.549438</td>\n      <td>0.408500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 62] Accuracy: 40.8500%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:59, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.043400</td>\n      <td>0.559054</td>\n      <td>0.815500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.402700</td>\n      <td>0.355572</td>\n      <td>0.884000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.225100</td>\n      <td>0.322962</td>\n      <td>0.895000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 63] Accuracy: 89.5000%\n   > Params: LR=1.00e-05, Rank=24, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.649900</td>\n      <td>1.565458</td>\n      <td>0.352000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.524500</td>\n      <td>1.495479</td>\n      <td>0.488500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.459400</td>\n      <td>1.452660</td>\n      <td>0.518500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 64] Accuracy: 51.8500%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.083200</td>\n      <td>0.614968</td>\n      <td>0.779000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.446300</td>\n      <td>0.444960</td>\n      <td>0.855500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.269000</td>\n      <td>0.382459</td>\n      <td>0.883500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 65] Accuracy: 88.3500%\n   > Params: LR=1.00e-05, Rank=24, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.670400</td>\n      <td>1.565493</td>\n      <td>0.353500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.518400</td>\n      <td>1.486120</td>\n      <td>0.505500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.447000</td>\n      <td>1.436659</td>\n      <td>0.520500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 66] Accuracy: 52.0500%\n   > Params: LR=1.00e-05, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.639300</td>\n      <td>1.528569</td>\n      <td>0.449000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.426200</td>\n      <td>1.345942</td>\n      <td>0.542000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.302900</td>\n      <td>1.293214</td>\n      <td>0.551000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   > [Trial 67] Accuracy: 55.1000%\n   > Params: LR=1.00e-05, Rank=24, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.650200</td>\n      <td>1.544160</td>\n      <td>0.437000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.450300</td>\n      <td>1.357396</td>\n      <td>0.543000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.302400</td>\n      <td>1.286615</td>\n      <td>0.549000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 68] Accuracy: 54.9000%\n   > Params: LR=1.00e-05, Rank=2, Alpha=64\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.656000</td>\n      <td>1.553864</td>\n      <td>0.461500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.485900</td>\n      <td>1.427761</td>\n      <td>0.532500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.377000</td>\n      <td>1.369470</td>\n      <td>0.535000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 69] Accuracy: 53.5000%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:59, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.053000</td>\n      <td>0.541627</td>\n      <td>0.817000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.405400</td>\n      <td>0.390524</td>\n      <td>0.868000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.222300</td>\n      <td>0.330345</td>\n      <td>0.898500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 70] Accuracy: 89.8500%\n   >>> New Swarm Best: 89.8500%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.959700</td>\n      <td>0.534444</td>\n      <td>0.824500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.396800</td>\n      <td>0.395744</td>\n      <td>0.864500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.235400</td>\n      <td>0.337843</td>\n      <td>0.888000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 71] Accuracy: 88.8000%\n   > Params: LR=1.00e-05, Rank=8, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:59, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.653700</td>\n      <td>1.556599</td>\n      <td>0.356000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.513600</td>\n      <td>1.479750</td>\n      <td>0.487500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.442800</td>\n      <td>1.438447</td>\n      <td>0.519000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 72] Accuracy: 51.9000%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.101200</td>\n      <td>0.560749</td>\n      <td>0.810500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.423900</td>\n      <td>0.386856</td>\n      <td>0.875500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.242800</td>\n      <td>0.339762</td>\n      <td>0.894000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 73] Accuracy: 89.4000%\n   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:59, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.958900</td>\n      <td>0.538500</td>\n      <td>0.821500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.384900</td>\n      <td>0.383997</td>\n      <td>0.874500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.221100</td>\n      <td>0.320329</td>\n      <td>0.897500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 74] Accuracy: 89.7500%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.054100</td>\n      <td>0.553665</td>\n      <td>0.801000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.411200</td>\n      <td>0.362874</td>\n      <td>0.879500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.234200</td>\n      <td>0.329823</td>\n      <td>0.892500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 75] Accuracy: 89.2500%\n   > Params: LR=2.00e-04, Rank=2, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.093000</td>\n      <td>0.610530</td>\n      <td>0.794000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.436900</td>\n      <td>0.407998</td>\n      <td>0.862000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.264800</td>\n      <td>0.356867</td>\n      <td>0.883500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 76] Accuracy: 88.3500%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:59, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.032500</td>\n      <td>0.544780</td>\n      <td>0.809500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.401700</td>\n      <td>0.425011</td>\n      <td>0.863500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.224100</td>\n      <td>0.343498</td>\n      <td>0.891000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 77] Accuracy: 89.1000%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.058400</td>\n      <td>0.598336</td>\n      <td>0.790000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.413100</td>\n      <td>0.411084</td>\n      <td>0.859000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.232600</td>\n      <td>0.336231</td>\n      <td>0.891000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 78] Accuracy: 89.1000%\n   > Params: LR=1.00e-05, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.647300</td>\n      <td>1.532838</td>\n      <td>0.397500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.431500</td>\n      <td>1.342070</td>\n      <td>0.541500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.298300</td>\n      <td>1.285979</td>\n      <td>0.548500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 79] Accuracy: 54.8500%\n   > Params: LR=1.00e-05, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.612500</td>\n      <td>1.537491</td>\n      <td>0.445500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.440500</td>\n      <td>1.361102</td>\n      <td>0.533500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.315700</td>\n      <td>1.307534</td>\n      <td>0.544500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 80] Accuracy: 54.4500%\n\n=== PSO EPOCH 5/5 ===\n   > Params: LR=1.00e-05, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.685100</td>\n      <td>1.577919</td>\n      <td>0.424500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.537300</td>\n      <td>1.514976</td>\n      <td>0.490000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.477900</td>\n      <td>1.473542</td>\n      <td>0.514000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 81] Accuracy: 51.4000%\n   > Params: LR=1.00e-05, Rank=4, Alpha=32\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.666700</td>\n      <td>1.569712</td>\n      <td>0.352000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.522700</td>\n      <td>1.485474</td>\n      <td>0.502500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.443400</td>\n      <td>1.432900</td>\n      <td>0.521500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 82] Accuracy: 52.1500%\n   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.012700</td>\n      <td>0.538329</td>\n      <td>0.822000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.386000</td>\n      <td>0.369709</td>\n      <td>0.885000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.215300</td>\n      <td>0.329103</td>\n      <td>0.898500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 83] Accuracy: 89.8500%\n   > Params: LR=1.00e-05, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.703400</td>\n      <td>1.573752</td>\n      <td>0.410000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.532800</td>\n      <td>1.511773</td>\n      <td>0.488000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.481500</td>\n      <td>1.477669</td>\n      <td>0.511000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 84] Accuracy: 51.1000%\n   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.960700</td>\n      <td>0.523225</td>\n      <td>0.819500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.386500</td>\n      <td>0.388101</td>\n      <td>0.879500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.242100</td>\n      <td>0.327719</td>\n      <td>0.898500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 85] Accuracy: 89.8500%\n   > Params: LR=1.00e-05, Rank=24, Alpha=8\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.669600</td>\n      <td>1.592755</td>\n      <td>0.385500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.561200</td>\n      <td>1.552613</td>\n      <td>0.399500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.536700</td>\n      <td>1.543166</td>\n      <td>0.430000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 86] Accuracy: 43.0000%\n   > Params: LR=1.00e-05, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.643500</td>\n      <td>1.524368</td>\n      <td>0.469000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.412300</td>\n      <td>1.325033</td>\n      <td>0.542500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.285400</td>\n      <td>1.275389</td>\n      <td>0.548500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 87] Accuracy: 54.8500%\n   > Params: LR=1.00e-05, Rank=24, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.670400</td>\n      <td>1.567027</td>\n      <td>0.354000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.536000</td>\n      <td>1.517166</td>\n      <td>0.465000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.491300</td>\n      <td>1.491596</td>\n      <td>0.496000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 88] Accuracy: 49.6000%\n   > Params: LR=1.00e-05, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.626100</td>\n      <td>1.495503</td>\n      <td>0.520500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.364300</td>\n      <td>1.279453</td>\n      <td>0.548500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.242100</td>\n      <td>1.235596</td>\n      <td>0.555500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 89] Accuracy: 55.5500%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.086600</td>\n      <td>0.540001</td>\n      <td>0.801500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.397200</td>\n      <td>0.387383</td>\n      <td>0.876500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.253900</td>\n      <td>0.341731</td>\n      <td>0.890000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 90] Accuracy: 89.0000%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.963600</td>\n      <td>0.535053</td>\n      <td>0.812500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.376600</td>\n      <td>0.345774</td>\n      <td>0.889000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.212700</td>\n      <td>0.326101</td>\n      <td>0.893500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   > [Trial 91] Accuracy: 89.3500%\n   > Params: LR=1.00e-05, Rank=24, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.632500</td>\n      <td>1.530381</td>\n      <td>0.495000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.409600</td>\n      <td>1.311970</td>\n      <td>0.548500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.270300</td>\n      <td>1.262494</td>\n      <td>0.553500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 92] Accuracy: 55.3500%\n   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.100500</td>\n      <td>0.539317</td>\n      <td>0.815500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.421500</td>\n      <td>0.388935</td>\n      <td>0.874500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.228000</td>\n      <td>0.333952</td>\n      <td>0.889500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 93] Accuracy: 88.9500%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.975700</td>\n      <td>0.545287</td>\n      <td>0.817500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.396800</td>\n      <td>0.363913</td>\n      <td>0.881000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.222900</td>\n      <td>0.337865</td>\n      <td>0.891000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 94] Accuracy: 89.1000%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.177800</td>\n      <td>0.620011</td>\n      <td>0.767000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.469800</td>\n      <td>0.384109</td>\n      <td>0.880000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.255600</td>\n      <td>0.339220</td>\n      <td>0.892000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 95] Accuracy: 89.2000%\n   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.074800</td>\n      <td>0.625636</td>\n      <td>0.775000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.435600</td>\n      <td>0.384732</td>\n      <td>0.875000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.241200</td>\n      <td>0.335172</td>\n      <td>0.904500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 96] Accuracy: 90.4500%\n   >>> New Swarm Best: 90.4500%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.102400</td>\n      <td>0.616226</td>\n      <td>0.780500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.412300</td>\n      <td>0.374323</td>\n      <td>0.878500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.227800</td>\n      <td>0.343720</td>\n      <td>0.896000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 97] Accuracy: 89.6000%\n   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.020000</td>\n      <td>0.544690</td>\n      <td>0.802000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.423900</td>\n      <td>0.405211</td>\n      <td>0.871000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.232500</td>\n      <td>0.352021</td>\n      <td>0.890500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 98] Accuracy: 89.0500%\n   > Params: LR=1.00e-05, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.653000</td>\n      <td>1.534674</td>\n      <td>0.458000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.414400</td>\n      <td>1.320317</td>\n      <td>0.541000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.277100</td>\n      <td>1.273134</td>\n      <td>0.549500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > [Trial 99] Accuracy: 54.9500%\n   > Params: LR=1.00e-05, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.654700</td>\n      <td>1.572332</td>\n      <td>0.365000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.533400</td>\n      <td>1.510455</td>\n      <td>0.472000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.475600</td>\n      <td>1.466406</td>\n      <td>0.509500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   > [Trial 100] Accuracy: 50.9500%\nResults saved to initial_results.csv\n\nBEST VALIDATION RESULT:\nAccuracy: 90.4500%\nRank: 4, Alpha: 96, LR: 2.00e-04\n\n============================================================\nELAPSED TIME: 108.44 m\n\n============================================================\n\n============================================================\nROBUSTNESS CHECK: TOP 5 CONFIGS x 3 NEW SEEDS\n============================================================\n\n--- Solution Rank 1 (Original Acc: 90.4500%) ---\n   > Retraining Seed 1/3 (Seed: 10042)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.097300</td>\n      <td>0.591759</td>\n      <td>0.809500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.425000</td>\n      <td>0.362183</td>\n      <td>0.885000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.236200</td>\n      <td>0.321496</td>\n      <td>0.891500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.1500%\n   > Retraining Seed 2/3 (Seed: 10043)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.085300</td>\n      <td>0.526102</td>\n      <td>0.809000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.415200</td>\n      <td>0.376145</td>\n      <td>0.881500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.216200</td>\n      <td>0.344495</td>\n      <td>0.896500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.6500%\n   > Retraining Seed 3/3 (Seed: 10044)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=4, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.088100</td>\n      <td>0.584154</td>\n      <td>0.797000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.402900</td>\n      <td>0.362958</td>\n      <td>0.884000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.229200</td>\n      <td>0.328413</td>\n      <td>0.892000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.2000%\n   >>> Stats | Mean Acc: 89.3333% | Std: 0.0022\n\n--- Solution Rank 2 (Original Acc: 89.8500%) ---\n   > Retraining Seed 1/3 (Seed: 10042)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:59, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.002300</td>\n      <td>0.585526</td>\n      <td>0.813000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.394400</td>\n      <td>0.360601</td>\n      <td>0.879000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.218000</td>\n      <td>0.316915</td>\n      <td>0.896500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.6500%\n   > Retraining Seed 2/3 (Seed: 10043)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.025700</td>\n      <td>0.513746</td>\n      <td>0.823000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.388400</td>\n      <td>0.380299</td>\n      <td>0.872000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.201600</td>\n      <td>0.331869</td>\n      <td>0.899000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.9000%\n   > Retraining Seed 3/3 (Seed: 10044)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.062900</td>\n      <td>0.587285</td>\n      <td>0.798000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.400300</td>\n      <td>0.377895</td>\n      <td>0.880500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.222100</td>\n      <td>0.351329</td>\n      <td>0.890000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.0000%\n   >>> Stats | Mean Acc: 89.5167% | Std: 0.0038\n\n--- Solution Rank 3 (Original Acc: 89.8500%) ---\n   > Retraining Seed 1/3 (Seed: 10042)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.993000</td>\n      <td>0.534786</td>\n      <td>0.829000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.385700</td>\n      <td>0.355571</td>\n      <td>0.885000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.216400</td>\n      <td>0.323555</td>\n      <td>0.895000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.5000%\n   > Retraining Seed 2/3 (Seed: 10043)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.009700</td>\n      <td>0.488259</td>\n      <td>0.839000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.364000</td>\n      <td>0.385289</td>\n      <td>0.881000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.191900</td>\n      <td>0.329795</td>\n      <td>0.898500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.8500%\n   > Retraining Seed 3/3 (Seed: 10044)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.038300</td>\n      <td>0.555704</td>\n      <td>0.807500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.371900</td>\n      <td>0.348998</td>\n      <td>0.890500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.202900</td>\n      <td>0.336126</td>\n      <td>0.894000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.4000%\n   >>> Stats | Mean Acc: 89.5833% | Std: 0.0019\n\n--- Solution Rank 4 (Original Acc: 89.8500%) ---\n   > Retraining Seed 1/3 (Seed: 10042)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.931900</td>\n      <td>0.551589</td>\n      <td>0.820500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.382400</td>\n      <td>0.352699</td>\n      <td>0.881000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.224900</td>\n      <td>0.322484</td>\n      <td>0.892000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.2000%\n   > Retraining Seed 2/3 (Seed: 10043)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.973900</td>\n      <td>0.520096</td>\n      <td>0.825000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.378600</td>\n      <td>0.390796</td>\n      <td>0.876000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.212800</td>\n      <td>0.337840</td>\n      <td>0.894000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.4000%\n   > Retraining Seed 3/3 (Seed: 10044)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=16, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.965000</td>\n      <td>0.567260</td>\n      <td>0.805500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.370200</td>\n      <td>0.337518</td>\n      <td>0.890000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.216300</td>\n      <td>0.318846</td>\n      <td>0.895500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.5500%\n   >>> Stats | Mean Acc: 89.3833% | Std: 0.0014\n\n--- Solution Rank 5 (Original Acc: 89.6000%) ---\n   > Retraining Seed 1/3 (Seed: 10042)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.053400</td>\n      <td>0.610630</td>\n      <td>0.800500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.402600</td>\n      <td>0.332573</td>\n      <td>0.887500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.224000</td>\n      <td>0.302939</td>\n      <td>0.898000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.8000%\n   > Retraining Seed 2/3 (Seed: 10043)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:59, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.063100</td>\n      <td>0.523710</td>\n      <td>0.811500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.382600</td>\n      <td>0.408763</td>\n      <td>0.870500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.199500</td>\n      <td>0.330642</td>\n      <td>0.899500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.9500%\n   > Retraining Seed 3/3 (Seed: 10044)... ","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"   > Params: LR=2.00e-04, Rank=8, Alpha=96\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:00, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.077200</td>\n      <td>0.579559</td>\n      <td>0.798000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.384200</td>\n      <td>0.371630</td>\n      <td>0.886500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.216300</td>\n      <td>0.336501</td>\n      <td>0.892000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Acc: 89.2000%\n   >>> Stats | Mean Acc: 89.6500% | Std: 0.0032\n\nTop solutions results saved to robust_results.csv\n\n============================================================\nBEST CONFIGURATION (Formatted Output):\n============================================================\nRank: 5.0\nMean Accuracy: 89.6500% ± 0.0032\nParams: LR=2.00e-04, r=8.0, alpha=96.0\n============================================================\n!!! ERROR in Run 1: name 'raw_robustness_data' is not defined\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/tmp/ipykernel_47/1756062320.py\", line 50, in <cell line: 0>\n    val_acc, best_params = run_single_optimization(run, data_bundle)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_47/1756062320.py\", line 19, in run_single_optimization\n    optimizer.evaluate_top_solutions_with_seeds(run_id=run_id, num_top=5, num_seeds=3)\n  File \"/tmp/ipykernel_47/628461661.py\", line 237, in evaluate_top_solutions_with_seeds\n    raw_df = pd.DataFrame(raw_robustness_data)\n                          ^^^^^^^^^^^^^^^^^^^\nNameError: name 'raw_robustness_data' is not defined\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nSTOCHASTICITY SUMMARY\n============================================================\n\nStochasticity results saved to pso_stochasticity_results.csv\n\n============================================================\nFINAL SINGLE RUN SUMMARY\n============================================================\n\nFinal results saved to pso_final_results.csv\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1756062320.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pso_optimization_results.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'final_results'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             optimizer.save_top_solutions_results(\n\u001b[1;32m    128\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"],"ename":"NameError","evalue":"name 'optimizer' is not defined","output_type":"error"}],"execution_count":12},{"cell_type":"markdown","source":"# **7.   Plot Generation**","metadata":{}},{"cell_type":"code","source":"def visualize_results():\n    # Target specifically Run 1 (The first full execution)\n    file_path = \"initial_results.csv\"\n    \n    # if not os.path.exists(file_path):\n    #     print(f\"Results file '{file_path}' not found.\")\n    #     return\n    \n    # Load data\n    df = pd.read_csv(file_path)\n    \n    # Ensure we are only looking at the Search Phase (Phase 1)\n    # Filter out any robustness trials if they accidentally got mixed in (Trial IDs > 9000)\n    if 'trial_id' in df.columns:\n        df = df[df['trial_id'] < 9000].copy()\n        \n    print(f\"Plotting Phase 1 Search Results: {len(df)} trials (20 particles x 5 epochs)\")\n    \n    plt.style.use('seaborn-v0_8-whitegrid')\n    fig, axes = plt.subplots(1, 3, figsize=(20,6))\n    \n    color = 'tab:blue'\n    run_name = \"Run 1 (Search Phase)\"\n    \n    # --- Plot 1: Convergence Trend ---\n    # Shows how the swarm found better solutions over the 80 trials\n    df['best_so_far'] = df['val_accuracy'].cummax()\n    \n    axes[0].plot(df['trial_id'], df['best_so_far'], label='Best So Far', color='red', linewidth=2)\n    axes[0].scatter(df['trial_id'], df['val_accuracy'], label='Individual Trials', color=color, alpha=0.5, s=15)\n    \n    # --- Plot 2: Accuracy Distribution ---\n    # Shows the spread of performance among the 20 individuals over 4 epochs\n    axes[1].hist(df['val_accuracy'], bins=15, alpha=0.7, label=run_name, color=color, edgecolor='black')\n    \n    # --- Plot 3: Training Time vs Accuracy ---\n    # if 'training_time_sec' in df.columns:\n    #     axes[2].scatter(df['training_time_sec'], df['val_accuracy'], \n    #                     label=run_name, color=color, alpha=0.6, edgecolors='w', s=40)\n    # else:\n    #     axes[2].text(0.5, 0.5, \"Time data missing\", ha='center')\n\n    # --- Formatting ---\n    axes[0].set_title(\"Search Convergence (Run 1)\", fontsize=14, fontweight='bold')\n    axes[0].set_xlabel(\"Trial ID (1-80)\", fontsize=12)\n    axes[0].set_ylabel(\"Validation Accuracy\", fontsize=12)\n    axes[0].legend()\n    axes[0].grid(True, linestyle='--', alpha=0.7)\n\n    axes[1].set_title(\"Accuracy Distribution (Run 1)\", fontsize=14, fontweight='bold')\n    axes[1].set_xlabel(\"Validation Accuracy\", fontsize=12)\n    axes[1].set_ylabel(\"Frequency\", fontsize=12)\n    \n    axes[2].set_title(\"Training Cost vs. Performance (Run 1)\", fontsize=14, fontweight='bold')\n    # axes[2].set_xlabel(\"Training Time (s)\", fontsize=12)\n    axes[2].set_ylabel(\"Validation Accuracy\", fontsize=12)\n    axes[2].grid(True, linestyle='--', alpha=0.7)\n    \n    plt.tight_layout()\n    plt.savefig('pso_visualization_run1.png')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:12:22.796653Z","iopub.execute_input":"2025-11-29T02:12:22.796921Z","iopub.status.idle":"2025-11-29T02:12:22.805139Z","shell.execute_reply.started":"2025-11-29T02:12:22.796904Z","shell.execute_reply":"2025-11-29T02:12:22.804356Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"visualize_results()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T02:08:59.385819Z","iopub.status.idle":"2025-11-29T02:08:59.386111Z","shell.execute_reply.started":"2025-11-29T02:08:59.385944Z","shell.execute_reply":"2025-11-29T02:08:59.385955Z"}},"outputs":[],"execution_count":null}]}